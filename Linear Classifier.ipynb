{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix rank =  11\n",
      "Matrix is full rank, unique solution exist.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "in_data = loadmat('CardioDataUpdatedFile.mat')\n",
    "# 11 features age, height, weight, gender, systolic blood pressure, diastolic blood pressure, cholesterol, glucose level, smoking, alcohol intake, and physical activity\n",
    "\n",
    "x = in_data['X']\n",
    "\n",
    "A = x[:,1:12] # Matrix A with all the features\n",
    "A[:,1] = A[:,1] / 365 # Change age from days to years. \n",
    "d = x[:,12] # Target variable d\n",
    "print('Matrix rank = ',np.linalg.matrix_rank(A))\n",
    "print('Matrix is full rank, unique solution exist.')\n",
    "# Now the Least squares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without any altercation to our data and using a simple least squares with all the features we get an error rate of 50.029999999999994\n",
      "\n",
      "Removing the data the features that are provided by the patient we get a similar error rate:  50.029999999999994\n"
     ]
    }
   ],
   "source": [
    "# Simple Least Square Sum using all features \n",
    "w = np.linalg.inv((A.T@A))@A.T@d\n",
    "error = np.mean(np.sign(A@w)!=d)\n",
    "print('Without any altercation to our data and using a simple least squares with all the features we get an error rate of', error*100)\n",
    "\n",
    "x_sub = A[:,0:8] # Using the first 8 features\n",
    "w_sub = np.linalg.inv((x_sub.T@x_sub))@x_sub.T@d\n",
    "error_sub = np.mean(np.sign(x_sub@w_sub)!=d)\n",
    "print('\\nRemoving the data the features that are provided by the patient we get a similar error rate: ', error_sub*100)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a simple SVD we get the same error 0.5003\n",
      "[0.49685714285714283, 0.502, 0.4948571428571429, 0.49685714285714283, 0.515, 0.4948571428571429, 0.509, 0.515, 0.49328571428571427, 0.509, 0.4948571428571429, 0.49328571428571427, 0.49814285714285716, 0.4948571428571429, 0.4997142857142857, 0.49814285714285716, 0.4992857142857143, 0.4997142857142857, 0.502, 0.4992857142857143]\n",
      "20\n",
      "Average error rate for truncated SVD is  50.029999999999994\n"
     ]
    }
   ],
   "source": [
    "# Using singular value decomposition \n",
    "A = A[:,0:8]\n",
    "U,s,VT = np.linalg.svd(A, full_matrices = False)\n",
    "w_pred = (1/s)*VT.transpose()@U.transpose()@d\n",
    "error = np.mean(np.sign(A@w_pred)!=d)\n",
    "print('Using a simple SVD we get the same error', error)\n",
    "\n",
    "# Know use training and validation sets\n",
    "# Sets of 70000\n",
    "x_train = np.array(list(range(0,56000)))\n",
    "hold_1 = np.array(list(range(56000,63000)))\n",
    "hold_2 = np.array(list(range(63000,70000)))\n",
    "x_train = np.vstack((x_train, (x_train+7000)%70000))\n",
    "hold_1 = np.vstack((hold_1, (hold_1+7000)%70000))\n",
    "hold_2 = np.vstack((hold_2, (hold_2+7000)%70000))                  \n",
    "                  \n",
    "                  \n",
    "for x in range(8):                  \n",
    "    x_train = np.vstack((x_train, (x_train[x+1]+7000)%70000))\n",
    "    hold_1 = np.vstack((hold_1, (hold_1[x+1]+7000)%70000))\n",
    "    hold_2 = np.vstack((hold_2, (hold_2[x+1]+7000)%70000))\n",
    "    \n",
    "\n",
    "# Now have different training and hold out sets \n",
    "err_list2 = []\n",
    "err_list3 = []\n",
    "r_prime = 0; # Assume r_prime = 0\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    for r in range(8):\n",
    "        X_train = A[x_train[i]]\n",
    "        U,s,VT = np.linalg.svd(X_train, full_matrices = False)\n",
    "        w_pred = (1/s[0:r+1])*VT.transpose()[:,0:r+1]@U.transpose()[0:r+1,:]@d[x_train[i]]\n",
    "        y_pred = np.sign(A[hold_1[i]]@w_pred)\n",
    "        err_list2.append(np.mean(d[hold_1[i]]!=y_pred))\n",
    "        if r > 0:\n",
    "            if err_list2[r_prime] > err_list2[r]:\n",
    "                r_prime = r\n",
    "        if r > 6: # Should only be ran once after finding optimal r\n",
    "            w_pred = VT.transpose()[:,0:r_prime+1]*(1/s[0:r_prime+1])@U.transpose()[0:r_prime+1,:]@d[x_train[i]]\n",
    "            y_pred = np.sign(A[hold_2[i]]@w_pred)\n",
    "            err_list3.append(np.mean(d[hold_2[i]]!=y_pred))\n",
    "       \n",
    "                \n",
    "    r_prime = 0\n",
    "    err_list2 = []\n",
    "    for r in range(8): # repeat for different combination of hold outs\n",
    "        X_train = A[x_train[i]]\n",
    "        U,s,VT = np.linalg.svd(X_train, full_matrices = False)\n",
    "        w_pred = (1/s[0:r+1])*VT.transpose()[:,0:r+1]@U.transpose()[0:r+1,:]@d[x_train[i]]\n",
    "        y_pred = np.sign(A[hold_2[i]]@w_pred)\n",
    "        err_list2.append(np.mean(d[hold_2[i]]!=y_pred))\n",
    "        if r > 0:\n",
    "            if err_list2[r_prime] > err_list2[r]:\n",
    "                r_prime = r\n",
    "            \n",
    "# Find error on hold out set 2 given ideal r\n",
    "        if r > 6: # Should only be ran once after finding optimal r\n",
    "            w_pred = VT.transpose()[:,0:r_prime+1]*(1/s[0:r_prime+1])@U.transpose()[0:r_prime+1,:]@d[x_train[i]]\n",
    "            y_pred = np.sign(A[hold_1[i]]@w_pred)\n",
    "            err_list3.append(np.mean(d[hold_1[i]]!=y_pred))\n",
    "            \n",
    "print(err_list3)\n",
    "print(len(err_list3))\n",
    "\n",
    "avg_error = np.mean(err_list3)\n",
    "print(\"Average error rate for truncated SVD is \", avg_error*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49685714285714283, 0.502, 0.4948571428571429, 0.49685714285714283, 0.515, 0.4948571428571429, 0.509, 0.515, 0.49328571428571427, 0.509, 0.4948571428571429, 0.49328571428571427, 0.49814285714285716, 0.4948571428571429, 0.4997142857142857, 0.49814285714285716, 0.4992857142857143, 0.4997142857142857, 0.502, 0.4992857142857143]\n",
      "20\n",
      "Average error rate for ridge regression is  50.029999999999994\n"
     ]
    }
   ],
   "source": [
    "# Method 2 = ridge regression \n",
    "    \n",
    "lambdas = [0,0.5,1,2,4,8,16]\n",
    "\n",
    "\n",
    "err_list2 = []\n",
    "err_list3 = []\n",
    "r_prime = 0; # Assume r_prime = 0\n",
    "\n",
    "# Find optimum r for w by testing on hold out set 1\n",
    "for i in range(10):\n",
    "    for r in range(7):\n",
    "        X_train = A[x_train[i]]\n",
    "        U,s,VT = np.linalg.svd(X_train, full_matrices = False)\n",
    "        sigma_inv = s / (s*s + lambdas[r])\n",
    "        w_pred = sigma_inv*VT.transpose()@U.transpose()@d[x_train[i]]\n",
    "        y_pred = np.sign(A[hold_1[i]]@w_pred)\n",
    "        err_list2.append(np.mean(d[hold_1[i]]!=y_pred))\n",
    "        if r > 0:\n",
    "            if err_list2[r_prime] > err_list2[r]:\n",
    "                r_prime = r\n",
    "                print('r prime', r_prime)\n",
    "        # Find error on hold out set 2 given ideal r\n",
    "        if r > 5: # Should only be ran once after finding optimal r\n",
    "            sigma_inv = s / (s*s + lambdas[r_prime])\n",
    "            w_pred = sigma_inv*VT.transpose()@U.transpose()@d[x_train[i]]\n",
    "            y_pred = np.sign(A[hold_2[i]]@w_pred)\n",
    "            err_list3.append(np.mean(d[hold_2[i]]!=y_pred))\n",
    "\n",
    "    r_prime = 0\n",
    "    err_list2 = []\n",
    "    \n",
    "    for r in range(7): # repeat for different combination of hold outs\n",
    "        X_train = A[x_train[i]]\n",
    "        U,s,VT = np.linalg.svd(X_train, full_matrices = False)\n",
    "        sigma_inv = s / (s*s + lambdas[r])\n",
    "        w_pred = sigma_inv*VT.transpose()@U.transpose()@d[x_train[i]]\n",
    "        y_pred = np.sign(A[hold_2[i]]@w_pred)\n",
    "        err_list2.append(np.mean(d[hold_2[i]]!=y_pred))\n",
    "        if r > 0:\n",
    "            if err_list2[r_prime] > err_list2[r]:\n",
    "                r_prime = r\n",
    "            \n",
    "# Find error on hold out set 2 given ideal r\n",
    "        if r > 5: # Should only be ran once after finding optimal r\n",
    "            sigma_inv = s / (s*s + lambdas[r])\n",
    "            w_pred = sigma_inv*VT.transpose()@U.transpose()@d[x_train[i]]\n",
    "            y_pred = np.sign(A[hold_1[i]]@w_pred)\n",
    "            err_list3.append(np.mean(d[hold_1[i]]!=y_pred))\n",
    "\n",
    "print(err_list3)\n",
    "print(len(err_list3))\n",
    "avg_error = np.mean(err_list3)\n",
    "print(\"Average error rate for ridge regression is \", avg_error*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM \n",
    "from sklearn import svm\n",
    "# Train classifier using linear SVM from SK Learn library\n",
    "# 90% f data to train\n",
    "# 10% of data to test\n",
    "\n",
    "x_train = np.array(list(range(0,63000)))\n",
    "x_val = np.array(list(range(63000,70000)))\n",
    "x_train = np.vstack((x_train, (x_train+7000)%70000))\n",
    "x_val = np.vstack((x_val, (x_val+7000)%70000))                                    \n",
    "                  \n",
    "for x in range(8):                  \n",
    "    x_train = np.vstack((x_train, (x_train[x+1]+7000)%70000))\n",
    "    x_val = np.vstack((x_val, (x_val[x+1]+7000)%70000))\n",
    "\n",
    "err_list2 = []\n",
    "for x in range(7):                  \n",
    "    clf = svm.SVC()\n",
    "    x_svm_tr = A[x_train[x]]\n",
    "    y_svm_tr = d[x_train[x]]\n",
    "    clf.fit(x_svm_tr, y_svm_tr)\n",
    "    ypred = clf.predict(A[x_val[x]])\n",
    "    err_list2.append(np.mean(d[x_val[x]]!=y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49685714285714283, 0.4948571428571429, 0.515, 0.509, 0.49328571428571427, 0.4948571428571429, 0.49814285714285716]\n",
      "0.5002857142857143\n"
     ]
    }
   ],
   "source": [
    "print(err_list2)\n",
    "print(np.mean(err_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
